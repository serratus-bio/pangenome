{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to be archived\n",
    "\n",
    "##S3-1: write fasta_genome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio.Seq import Seq\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "from Bio.Align import MultipleSeqAlignment\n",
    "from glob import glob\n",
    "import json\n",
    "from typing import Generator,Tuple,Optional,Iterable,Callable\n",
    "import pandas as pd\n",
    "# from Bio import Align\n",
    "from pathlib import Path\n",
    "def iter_match(genome_dict:dict)->Generator[Tuple[dict,dict],None,None]:\n",
    "    '''\n",
    "    same itermath as `extract_domains.py`\n",
    "    put here for convienience\n",
    "    '''\n",
    "    for orf in genome_dict['results'][0]['openReadingFrames']:\n",
    "        for match in orf['protein']['matches']:\n",
    "            yield (orf,match)\n",
    "\n",
    "def convert_fasta(gfile:str):\n",
    "    '''\n",
    "    gfile: json of interproscan;\n",
    "    '''\n",
    "    # o=[]\n",
    "    o_dict={}\n",
    "    b=0\n",
    "        # print('\\n\\n##'+gfile.split('/')[1].replace(':genome.json',''))\n",
    "    # genome_name=gfile.split('/')[1].replace(':genome.json','')\n",
    "    genome_dict=json.load(open(gfile))\n",
    "    for orf,match in iter_match(genome_dict):\n",
    "        seq=orf['protein']['sequence']\n",
    "        if len(match['locations'])==1:\n",
    "            _=match['locations'][0]\n",
    "            b,e=_['start'],_['end']\n",
    "            seq_=seq[b:e]\n",
    "            name=match['signature']['accession']\n",
    "            # o.append(f'>{name}\\n{seq_}')\n",
    "            o_dict[name]=seq_\n",
    "        else:\n",
    "            for i,_ in enumerate(match['locations']):\n",
    "                b,e=_['start'],_['end']\n",
    "                seq_=seq[b:e]\n",
    "                name=match['signature']['accession']+'#'+str(i)\n",
    "                # o.append(f'>{name}\\n{seq_}')\n",
    "                o_dict[name]=seq_\n",
    "    # print('\\n'.join(o),file=open('nido-rdrp.fasta','w'))  \n",
    "    return o_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_single_genome_fasta(file_limit:str='zika_subset/*:genome.json',\n",
    "                odir:str='zika_fasta_genome',\n",
    "                convert:Callable[[str], str]=lambda x: Path(x).name.replace('.json','.fasta'),\n",
    "                ):\n",
    "    '''\n",
    "    `file_limit`: decides json to be extract\n",
    "    `odir`: dir to save those fasta\n",
    "    `convert`: callable from glob(file_limit)'s str to filename of output\n",
    "    '''\n",
    "    # o={}\n",
    "    odir=Path(odir)\n",
    "    odir.mkdir(mode=511,exist_ok=True)\n",
    "    for i in glob(file_limit):\n",
    "        o_dict=convert_fasta(i)\n",
    "        with open(str(odir/convert(i)),'w') as f:\n",
    "            fastas='\\n'.join([f'>{k1}\\n{v1}' for k1,v1 in o_dict.items()])\n",
    "            f.write(fastas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in ['zika','ebola','measles']:\n",
    "    write_single_genome_fasta(file_limit=f'{i}_subset/*:genome.json',\n",
    "                odir=f'{i}_fasta_genome')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rdrp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
