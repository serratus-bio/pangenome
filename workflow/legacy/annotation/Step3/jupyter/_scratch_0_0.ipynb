{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Sort', 'Isolate Sort', 'Realm', 'Subrealm', 'Kingdom', 'Subkingdom',\n",
       "       'Phylum', 'Subphylum', 'Class', 'Subclass', 'Order', 'Suborder',\n",
       "       'Family', 'Subfamily', 'Genus', 'Subgenus', 'Species',\n",
       "       'Exemplar or additional isolate', 'Virus name(s)',\n",
       "       'Virus name abbreviation(s)', 'Virus isolate designation',\n",
       "       'Virus GENBANK accession', 'Virus REFSEQ accession', 'Genome coverage',\n",
       "       'Genome composition', 'Host source'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "vmr=pd.read_csv('VMR_MSL38_v2.csv')\n",
    "vmr.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO logging control!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zika virus: Sort=7210-7213, Genus=Orthoflavivirus, Family=Flaviviridae\n",
    "Ebola virus: Sort=8655, Genus=Orthoebolavirus, Family=Filoviridae\n",
    "measles virus: Sort=8828 Genus=Morbillivirus Family=Paramyxoviridae\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Family:\n",
      "Flaviviridae,148\n",
      "Filoviridae,16\n",
      "Paramyxoviridae,87\n",
      "Genus:\n",
      "Orthoflavivirus,79\n",
      "Orthoebolavirus,6\n",
      "Morbillivirus,7\n"
     ]
    }
   ],
   "source": [
    "print('Family:')\n",
    "for i in ['Flaviviridae','Filoviridae','Paramyxoviridae']:\n",
    "    l=len(vmr[vmr['Family']==i])\n",
    "    print(f'{i},{l}')\n",
    "print('Genus:')\n",
    "for i in ['Orthoflavivirus','Orthoebolavirus','Morbillivirus']:\n",
    "    l=len(vmr[vmr['Genus']==i])\n",
    "    print(f'{i},{l}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## S1: \n",
    "\n",
    "*-subset: subset of vmr with additional col of \"true_access\",\"true_name\";\n",
    "\n",
    "*-fetch_names.list: (list of scan json)\n",
    "\n",
    "check: Step1:2_3,ipynb, do_efetch.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List,Dict\n",
    "from warnings import warn\n",
    "def robust_split(s:str,split:str)->List[str]:\n",
    "    return [i.strip() for i in s.split(split)]\n",
    "\n",
    "def get_genbank_id(accession:str)->Dict[str,str]:\n",
    "    assert isinstance(accession,str),f'accession: {accession} is not a str!'\n",
    "    o={}\n",
    "    holder_token=0\n",
    "    if ';' in accession:\n",
    "        for sub_a in robust_split(accession,';'):\n",
    "            if ':' in sub_a:\n",
    "                subk,subv=robust_split(sub_a,':')\n",
    "                o[subk]=subv\n",
    "            else:\n",
    "                o[f'{holder_token}']=sub_a\n",
    "                holder_token+=1\n",
    "    else:\n",
    "        if \":\" in accession:\n",
    "            subk,subv=robust_split(accession,':')\n",
    "            o[subk]=subv\n",
    "        else:\n",
    "            o['_']=accession\n",
    "    return o\n",
    "\n",
    "def get_correct_name(name:str)->str:\n",
    "    \"some names block contains multiple name sep by ';'\"\n",
    "    assert isinstance(name,str),f'valid input: {name}'\n",
    "    if ';' in name:\n",
    "        warn(f'multiple names: {name},use the first one')\n",
    "        return robust_split(name,';')[0]\n",
    "    else:\n",
    "        return name\n",
    "    \n",
    "def is_multiple_access(access:Dict[str,str])->bool:\n",
    "    ''' `False`: one seg; `True`:c segs '''\n",
    "    if '_' in access:\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "    \n",
    "def get_file_stem(virus_series:pd.Series,\n",
    "    access_col='true_access',name_col='true_name')->List[str]:\n",
    "    _=virus_series\n",
    "    access:Dict[str,str]= _[access_col]\n",
    "    if not is_multiple_access(_[access_col]):\n",
    "        return [f\"{_[name_col]}||{access['_']}\"]\n",
    "    else:\n",
    "        return [f\"{_[name_col]}|{k}|{v}\" for k,v in access.items()]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from subprocess import run\n",
    "\n",
    "def extract_subset(col:str='Family',kw:str='Flaviviridae',\n",
    "                   odir='zika_subset',all_scan='scan_result',\n",
    "                   vmr:pd.DataFrame=vmr):\n",
    "    '''\n",
    "    `col`,`kw`: selection condition on `all_scan`\n",
    "    \n",
    "    `odir`: recommended suffix of '_subset'\n",
    "    '''\n",
    "    odir,all_scan=Path(odir),Path(all_scan)\n",
    "    #\n",
    "    odir.mkdir(mode=511,exist_ok=True)\n",
    "    sub_list=vmr[vmr[col]==kw].copy(deep=True)\n",
    "    sub_list['true_access']=sub_list['Virus GENBANK accession'].apply(get_genbank_id)\n",
    "    sub_list['true_name']=sub_list['Virus name abbreviation(s)'].apply(get_correct_name)\n",
    "\n",
    "    #save subset.csv\n",
    "    file_stems=[]\n",
    "    for _,s in sub_list.iterrows():\n",
    "        file_stems.extend(get_file_stem(s))\n",
    "    sub_list.to_csv(odir.with_suffix('.csv'),index=False)\n",
    "\n",
    "    #write hard copy of subset\n",
    "    err_file=odir.with_suffix('.err')\n",
    "    with open(str(err_file),'w') as f:\n",
    "        for i in file_stems:\n",
    "            gf=all_scan/f'{i}:genome.json'\n",
    "            sf=all_scan/f'{i}:segs.json'\n",
    "            if not gf.is_file():\n",
    "                print(f'not found: {gf}', file=f)\n",
    "            else:\n",
    "                run(['cp',gf.absolute(),(odir/gf.name).absolute()])\n",
    "            if not sf.is_file():\n",
    "                print(f'not found: {sf}', file=f)\n",
    "            else:\n",
    "                run(['cp',sf.absolute(),(odir/sf.name).absolute()])\n",
    "    \n",
    "    #write subset list\n",
    "    list_file=odir.with_suffix('.list')\n",
    "    with open(str(list_file),'w') as f:\n",
    "        for i in odir.iterdir():\n",
    "            print(i.name,file=f)\n",
    "        \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "family_dict={\n",
    "    'zika':'Flaviviridae',\n",
    "    'ebola':'Filoviridae',\n",
    "    'measles':'Paramyxoviridae'\n",
    "}\n",
    "for k,v in family_dict.items():\n",
    "    extract_subset(kw=v,odir=f'{k}_subset')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## S2: \n",
    "\n",
    "*domains.csv: every domain in the subset entries\n",
    "\n",
    "check: Step1:extract_domains.py\n",
    "\n",
    "\n",
    "*accession-annotation.csv: the unique accession-annotation col in domains.csv\n",
    "\n",
    "check: Step2:scatter_plot.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from typing import Generator,Tuple\n",
    "import json\n",
    "import pandas as pd\n",
    "def iter_match(genome_dict:dict)->Generator[Tuple[dict,dict],None,None]:\n",
    "    '''\n",
    "    in a scan result json dict (of nt),\n",
    "    iter through all orf-match pairs\n",
    "    '''\n",
    "    for orf in genome_dict['results'][0]['openReadingFrames']:\n",
    "        for match in orf['protein']['matches']:\n",
    "            yield (orf,match)\n",
    "def get_domains(file_limit='nido_subset/*:genome.json',\n",
    "                ostem='nido-domains'):\n",
    "    '''\n",
    "    get all PFAM hit from files matching the `file_limit` \n",
    "    and save to ${ostem}.csv\n",
    "    \n",
    "    entries of output scv: \n",
    "    genome_name,genome_length,domain_accession,strand,\n",
    "    start,end,hmmStart,hmmEnd,evalue,domain_annotation\n",
    "    \n",
    "    accession: interproscan id\n",
    "    '''\n",
    "    o=[]\n",
    "    for gfile in glob(file_limit):\n",
    "        # print('\\n\\n##'+gfile.split('/')[1].replace(':genome.json',''))\n",
    "        genome_name=gfile.split('/')[1].replace(':genome.json','')\n",
    "        genome_dict=json.load(open(gfile))\n",
    "        genome_length=len(genome_dict['results'][0]['sequence'])\n",
    "        for orf,match in iter_match(genome_dict):\n",
    "            orf_info=orf['start'],orf['end'],orf['strand']\n",
    "            match_info=(match['signature']['accession'],\n",
    "                    f\"{match['signature']['name']}:{match['signature']['description']}\",\n",
    "                    match['signature']['signatureLibraryRelease']['library'])\n",
    "            if match_info[2]=='PFAM': #'PROSITE_PROFILES'\n",
    "                for loc in match['locations']:\n",
    "                    data=(loc['start'],\n",
    "                        loc['end'],\n",
    "                        loc['hmmStart'],\n",
    "                        loc['hmmEnd'],\n",
    "                        loc['evalue'])\n",
    "                    entry={}\n",
    "                    entry['genome_name']=genome_name\n",
    "                    entry['genome_length']=genome_length\n",
    "                    entry['domain_accession']=match_info[0]\n",
    "                    \n",
    "                    entry['strand']=orf_info[2]\n",
    "                    if entry['strand']=='SENSE':\n",
    "                        entry['start']=orf_info[0]+data[0]*3\n",
    "                        entry['end']=orf_info[0]+data[1]*3\n",
    "                    else:\n",
    "                        entry['start']=orf_info[1]-data[1]*3\n",
    "                        entry['end']=orf_info[1]-data[0]*3\n",
    "                    entry['hmmStart']=data[2]\n",
    "                    entry['hmmEnd']=data[3]\n",
    "                    entry['evalue']=data[4]\n",
    "                    entry['domain_annotation']=match_info[1]\n",
    "                    o.append(entry)\n",
    "    \n",
    "    domains=pd.DataFrame(o)\n",
    "    opath=Path(ostem).with_suffix('.csv')\n",
    "    domains.to_csv(opath,index=False)\n",
    "    \n",
    "    acan_dict={}\n",
    "    acan_dict['accession'],acan_dict['annotation']=[],[]\n",
    "    for accession in domains['domain_accession'].unique():\n",
    "        annot=domains[domains['domain_accession']==accession].iloc[0]['domain_annotation']\n",
    "        acan_dict['accession'].append(accession)\n",
    "        acan_dict['annotation'].append(annot)\n",
    "        \n",
    "    domain_annotations=pd.DataFrame(acan_dict)\n",
    "    domain_annotations.to_csv(Path(ostem+'-acan').with_suffix('.csv'),index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "family_dict={\n",
    "    'zika':'Flaviviridae',\n",
    "    'ebola':'Filoviridae',\n",
    "    'measles':'Paramyxoviridae'\n",
    "}\n",
    "\n",
    "\n",
    "for k,v in family_dict.items():\n",
    "    get_domains(file_limit=f'{k}_subset/*:genome.json',\n",
    "                ostem=f'{k}-domains')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## S3:\n",
    "*sort.list\n",
    "\n",
    "check Step1: extract_domains.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio.Seq import Seq\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "from Bio.Align import MultipleSeqAlignment\n",
    "from glob import glob\n",
    "import json\n",
    "from typing import Generator,Tuple,Optional,Iterable\n",
    "import pandas as pd\n",
    "from Bio import Align\n",
    "\n",
    "def iter_match(genome_dict:dict)->Generator[Tuple[dict,dict],None,None]:\n",
    "    '''\n",
    "    same itermath as `extract_domains.py`\n",
    "    put here for convienience\n",
    "    '''\n",
    "    for orf in genome_dict['results'][0]['openReadingFrames']:\n",
    "        for match in orf['protein']['matches']:\n",
    "            yield (orf,match)\n",
    "\n",
    "def get_fasta(accession:str='PF00680',file_limit='nido_subset/*:genome.json'):\n",
    "    '''\n",
    "    file_limit: restrict the file to search for the accession;\n",
    "    accession: in each file, the accession to fetch;\n",
    "    '''\n",
    "    o=[]\n",
    "    o_dict={}\n",
    "    b=0\n",
    "    for gfile in glob(file_limit):\n",
    "        # print('\\n\\n##'+gfile.split('/')[1].replace(':genome.json',''))\n",
    "        genome_name=gfile.split('/')[1].replace(':genome.json','')\n",
    "        genome_dict=json.load(open(gfile))\n",
    "        for orf,match in iter_match(genome_dict):\n",
    "            if match['signature']['accession']==accession:\n",
    "                seq=orf['protein']['sequence']\n",
    "                if len(match['locations'])==1:\n",
    "                    _=match['locations'][0]\n",
    "                    b,e=_['start'],_['end']\n",
    "                    rdrp_seq=seq[b:e]\n",
    "                    rdrp_name=genome_name\n",
    "                    o.append(f'>{rdrp_name}\\n{rdrp_seq}')\n",
    "                    o_dict[rdrp_name]=rdrp_seq\n",
    "                else:\n",
    "                    for i,_ in enumerate(match['locations']):\n",
    "                        b,e=_['start'],_['end']\n",
    "                        rdrp_seq=seq[b:e]\n",
    "                        rdrp_name=genome_name+'#'+str(i)\n",
    "                        o.append(f'>{rdrp_name}\\n{rdrp_seq}')\n",
    "                        o_dict[rdrp_name]=rdrp_seq\n",
    "    # print('\\n'.join(o),file=open('nido-rdrp.fasta','w'))  \n",
    "    return o_dict,o\n",
    "\n",
    "def write_fasta(file_limit:str='nido_subset/*:genome.json',\n",
    "                odir:str='cov19-hits',suffix:str='',\n",
    "                used_domain:Iterable[str]=['PF00680'],\n",
    "                ):\n",
    "    '''\n",
    "    `file_limit`: decides json to be extract\n",
    "    `odir`: dir to save those fasta\n",
    "    `used_domain`: decide which domains will be extracted.\n",
    "    '''\n",
    "    o={}\n",
    "    odir=Path(odir)\n",
    "    odir.mkdir(mode=511,exist_ok=True)\n",
    "    for i in used_domain:\n",
    "        o[i]=get_fasta(i,file_limit)[0]\n",
    "    for k,v in o.items():\n",
    "        with open(str(odir/f'{k}{suffix}.fasta'),'w') as f:\n",
    "            fastas='\\n'.join([f'>{k1}\\n{v1}' for k1,v1 in v.items()])\n",
    "            f.write(fastas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_genome_dict={\n",
    "    'zika':'ZIKV||AY632535',\n",
    "    'ebola':'EBOV||AF086833',\n",
    "    'measles':'MeV||AB016162'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,v in ref_genome_dict.items():\n",
    "    write_fasta(file_limit=f'{k}_subset/*:genome.json',\n",
    "                odir=f'{k}_fasta',\n",
    "                used_domain=pd.read_csv(f'{k}-domains-acan.csv')['accession'])\n",
    "    write_fasta(file_limit=f'{k}_subset/{v}:genome.json',\n",
    "            odir=f'{k}_fasta',\n",
    "            suffix='-ref',\n",
    "            used_domain=pd.read_csv(f'{k}-domains-acan.csv')['accession'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from subprocess import run,PIPE\n",
    "\n",
    "def cal_diamond_identity(wdir:str='cov19-hits',\n",
    "                     ref_suffix:str='-ref'):\n",
    "    for i in Path(wdir).iterdir():\n",
    "        stem=i.stem\n",
    "        if ref_suffix not in stem and i.suffix=='.fasta':\n",
    "            _=run(['./diamond',\n",
    "                    'makedb',\n",
    "                    '--in',\n",
    "                    str(i),\n",
    "                    '-d',\n",
    "                    str(i.with_name(f'{stem}-reference'))],\n",
    "                    stdout=PIPE,\n",
    "                    stderr=PIPE)\n",
    "            _=run(['./diamond','blastp',\n",
    "                '-d',str(i.with_name(f'{stem}-reference')),\n",
    "                    '-q',str(i.with_name(f'{stem}{ref_suffix}.fasta')),\n",
    "                    '-o',str(i.with_name(f'{stem}-match.tsv')),\n",
    "                    '--id', '0' ,\n",
    "                    '--max-target-seqs', '300', \n",
    "                    '--header', 'verbose', \n",
    "                    '--min-score', '0', \n",
    "                    '--query-cover', '0', \n",
    "                    '--subject-cover', '0', \n",
    "                    '--evalue','1'],\n",
    "                    stdout=PIPE,\n",
    "                    stderr=PIPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,v in ref_genome_dict.items():\n",
    "    cal_diamond_identity(f'{k}_fasta')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
