{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pangenome dataset export"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/miniconda3/envs/rnalab/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "## Notebook config\n",
    "\n",
    "import sys\n",
    "if '../' not in sys.path:\n",
    "    sys.path.append(\"../\")\n",
    "%load_ext dotenv\n",
    "%reload_ext dotenv\n",
    "%dotenv\n",
    "\n",
    "# Notebook imports\n",
    "import os\n",
    "import ast\n",
    "\n",
    "from graphdatascience import GraphDataScience\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_DIR = './dataset/'\n",
    "PROJECTION_NAME_PREFIX = 'dataset_projection_'\n",
    "\n",
    "NEO4J_URI = os.environ.get('NEO4J_URI')\n",
    "NEO4J_USER = os.environ.get('NEO4J_USER')\n",
    "NEO4J_PASSWORD = os.environ.get('NEO4J_PASSWORD')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create GDS projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GDS utils\n",
    "\n",
    "graph_config = {\n",
    "    'node_spec': {\n",
    "        'Fasta': {},\n",
    "        'Hit': {},\n",
    "        'HitFamily': {},\n",
    "        'HitRegion': {},\n",
    "    },\n",
    "    'relationship_spec' : {\n",
    "        'hasHit': {'orientation': 'NATURAL', 'properties': {'score': {'defaultValue': 1}}},\n",
    "        'hasRegion': {'orientation': 'NATURAL', 'properties': {'score': {'defaultValue': 1}}},\n",
    "        'hasAffiliate': {'orientation': 'NATURAL', 'properties': {'coverage': {'defaultValue': 1}}},\n",
    "        'hasMember': {'orientation': 'NATURAL', 'properties': {'probab': {'defaultValue': 1}}},\n",
    "        'hasDownstream': {'orientation': 'NATURAL', 'properties': {'score': {'defaultValue': 1}}},\n",
    "    },\n",
    "}\n",
    "\n",
    "def get_pg_client():\n",
    "    return GraphDataScience(NEO4J_URI, auth=(NEO4J_USER, NEO4J_PASSWORD))\n",
    "\n",
    "def get_kg_connection():\n",
    "    return GraphDataScience(\n",
    "        os.environ.get('NEO4J_KG_URI'),\n",
    "        auth=(\n",
    "            os.environ.get('NEO4J_KG_USER'), \n",
    "            os.environ.get('NEO4J_KG_PASSWORD'),\n",
    "        )\n",
    "    )\n",
    "\n",
    "def get_projection_name(version=1):\n",
    "    return PROJECTION_NAME_PREFIX + str(version)\n",
    "\n",
    "def get_projection(gds, projection_name):\n",
    "    if gds.graph.exists(projection_name)['exists']:\n",
    "        return gds.graph.get(projection_name)\n",
    "    projection = gds.graph.project(\n",
    "        graph_name=projection_name,\n",
    "        node_spec=list(graph_config['node_spec'].keys()),\n",
    "        relationship_spec=graph_config['relationship_spec'],\n",
    "    )\n",
    "    return projection\n",
    "\n",
    "def delete_projection(gds, projection_name):\n",
    "    if gds.graph.exists(projection_name)['exists']:\n",
    "        gds.graph.drop(gds.graph.get(projection_name))\n",
    "\n",
    "# At least one common node property is needed to use the gds node export function\n",
    "def add_degree_property(gds, projection_name):\n",
    "    df_degree = gds.degree.mutate(\n",
    "        G=gds.graph.get(projection_name),\n",
    "        mutateProperty='degree',\n",
    "        nodeLabels=[\"*\"],\n",
    "        relationshipTypes=[\"*\"],\n",
    "    )\n",
    "\n",
    "def add_fastrp_embedding(gds, projection_name):\n",
    "    df_fastrp = gds.fastRP.mutate(\n",
    "        G=gds.graph.get(projection_name),\n",
    "        mutateProperty='fastrp',\n",
    "        randomSeed=42,\n",
    "        # relationshipWeightProperty='weight',\n",
    "        nodeLabels=[\n",
    "            'Fasta',\n",
    "            'Hit',\n",
    "            'HitFamily',\n",
    "            'HitRegion',\n",
    "        ],\n",
    "        relationshipTypes=[\n",
    "            \"hasHit\",\n",
    "            \"hasRegion\",\n",
    "            \"hasAffiliate\",\n",
    "            \"hasMember\",\n",
    "            \"hasDownstream\",\n",
    "        ],\n",
    "        embeddingDimension=128,\n",
    "        normalizationStrength=-0.5,\n",
    "        # nodeSelfInfluence=2,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GraphCreateResult(graph=Graph({'graphName': 'dataset_projection_1', 'nodeCount': 148782, 'relationshipCount': 393619, 'database': 'neo4j', 'configuration': {'relationshipProjection': {'hasHit': {'aggregation': 'DEFAULT', 'orientation': 'NATURAL', 'indexInverse': False, 'properties': {'score': {'aggregation': 'DEFAULT', 'property': 'score', 'defaultValue': 1}}, 'type': 'hasHit'}, 'hasMember': {'aggregation': 'DEFAULT', 'orientation': 'NATURAL', 'indexInverse': False, 'properties': {'probab': {'aggregation': 'DEFAULT', 'property': 'probab', 'defaultValue': 1}}, 'type': 'hasMember'}, 'hasRegion': {'aggregation': 'DEFAULT', 'orientation': 'NATURAL', 'indexInverse': False, 'properties': {'score': {'aggregation': 'DEFAULT', 'property': 'score', 'defaultValue': 1}}, 'type': 'hasRegion'}, 'hasDownstream': {'aggregation': 'DEFAULT', 'orientation': 'NATURAL', 'indexInverse': False, 'properties': {'score': {'aggregation': 'DEFAULT', 'property': 'score', 'defaultValue': 1}}, 'type': 'hasDownstream'}, 'hasAffiliate': {'aggregation': 'DEFAULT', 'orientation': 'NATURAL', 'indexInverse': False, 'properties': {'coverage': {'aggregation': 'DEFAULT', 'property': 'coverage', 'defaultValue': 1}}, 'type': 'hasAffiliate'}}, 'readConcurrency': 4, 'relationshipProperties': {}, 'nodeProperties': {}, 'jobId': '8275ca36-2660-464b-a082-5d95aa6e6cdb', 'nodeProjection': {'HitRegion': {'label': 'HitRegion', 'properties': {}}, 'Hit': {'label': 'Hit', 'properties': {}}, 'HitFamily': {'label': 'HitFamily', 'properties': {}}, 'Fasta': {'label': 'Fasta', 'properties': {}}}, 'logProgress': True, 'creationTime': neo4j.time.DateTime(2024, 4, 30, 23, 35, 57, 289414697, tzinfo=<UTC>), 'validateRelationships': False, 'sudo': False}, 'schema': {'graphProperties': {}, 'nodes': {'HitRegion': {'degree': 'Float (DefaultValue(NaN), TRANSIENT)'}, 'Hit': {'degree': 'Float (DefaultValue(NaN), TRANSIENT)'}, 'HitFamily': {'degree': 'Float (DefaultValue(NaN), TRANSIENT)'}, 'Fasta': {'degree': 'Float (DefaultValue(NaN), TRANSIENT)'}}, 'relationships': {'hasHit': {'score': 'Float (DefaultValue(1), PERSISTENT, Aggregation.NONE)'}, 'hasMember': {'probab': 'Float (DefaultValue(1), PERSISTENT, Aggregation.NONE)'}, 'hasRegion': {'score': 'Float (DefaultValue(1), PERSISTENT, Aggregation.NONE)'}, 'hasDownstream': {'score': 'Float (DefaultValue(1), PERSISTENT, Aggregation.NONE)'}, 'hasAffiliate': {'coverage': 'Float (DefaultValue(1), PERSISTENT, Aggregation.NONE)'}}}, 'memoryUsage': None}), result=nodeProjection            {'HitRegion': {'label': 'HitRegion', 'properti...\n",
      "relationshipProjection    {'hasHit': {'aggregation': 'DEFAULT', 'orienta...\n",
      "graphName                                              dataset_projection_1\n",
      "nodeCount                                                            148782\n",
      "relationshipCount                                                    393619\n",
      "projectMillis                                                           345\n",
      "Name: 0, dtype: object)\n"
     ]
    }
   ],
   "source": [
    "# Create GDS projection\n",
    "\n",
    "version = 1\n",
    "projection_name = get_projection_name(version)\n",
    "gds = get_pg_client()\n",
    "delete_projection(gds, projection_name)\n",
    "projection = get_projection(gds, projection_name)\n",
    "add_degree_property(gds, projection_name)\n",
    "print(projection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export Pangenome Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMBER_OF_NODES = 148782\n",
    "NUMBER_OF_EDGES = 393619"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/miniconda3/envs/rnalab/lib/python3.12/site-packages/graphdatascience/query_runner/neo4j_query_runner.py:222: RuntimeWarning: One of the property names in your query is not available in the database, make sure you didn't misspell it or that the label is available when you run this statement in your application (the missing property name is: hit_beginhit_end)\n",
      "  warnings.warn(warning)\n"
     ]
    }
   ],
   "source": [
    "# Export nodes from projection to df\n",
    "\n",
    "def export_nodes_from_projection(property):\n",
    "    nodes = gds.graph.nodeProperties.stream(\n",
    "        get_projection(gds, get_projection_name()),\n",
    "        node_properties=[property],\n",
    "        separate_property_columns=True,\n",
    "        db_node_properties=[\n",
    "            'accession',\n",
    "            'name',\n",
    "            'annotation',\n",
    "            'subtype',\n",
    "            'std_length',\n",
    "            'source',\n",
    "            'taxonomy',\n",
    "            'circular',\n",
    "            'begin',\n",
    "            'end',\n",
    "            'hit_begin'\n",
    "            'hit_end',\n",
    "            'frame',\n",
    "            'strand',\n",
    "        ],\n",
    "        listNodeLabels=True,\n",
    "    )\n",
    "    nodes['nodeLabels'] = nodes['nodeLabels'].apply(lambda x: x[0])\n",
    "    return nodes\n",
    "\n",
    "\n",
    "nodes = export_nodes_from_projection('degree')\n",
    "\n",
    "assert nodes.shape[0] == NUMBER_OF_NODES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enrich nodes df and save to csv\n",
    "\n",
    "## Enrich Genomes with taxonomic labels from ICTV string\n",
    "def get_taxonomy_by_idx(tax_str, idx):\n",
    "    try:\n",
    "        value = tax_str.split(';')[idx].strip()\n",
    "        if value == '' or value == 'Null':\n",
    "            return None\n",
    "        return value\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def enrich_data_with_tax_labels(df):\n",
    "    rank_index = {\n",
    "        'clade': 0,\n",
    "        'kingdom': 2,\n",
    "        'phylum': 4,\n",
    "        'class': 6,\n",
    "        'order': 8,\n",
    "        'family': 10,\n",
    "        'genus': 12,\n",
    "        'species': 14,\n",
    "    }\n",
    "    for rank in ['species', 'genus', 'family', 'order', 'class', 'phylum']:\n",
    "        df[rank] = None\n",
    "        df.loc[df['nodeLabels'] == 'Fasta', rank] = df.loc[\n",
    "            df['nodeLabels'] == 'Fasta', 'taxonomy'].apply(get_taxonomy_by_idx, args=[rank_index[rank]])\n",
    "    return df\n",
    "\n",
    "## nodeId is not stable in neo4j, instead add a reference to a stable node attribute\n",
    "def set_node_app_id(df):\n",
    "    config = {\n",
    "        'Fasta': 'accession',\n",
    "        'Hit': 'name',\n",
    "        'HitFamily': 'accession',\n",
    "        'HitRegion': 'name',\n",
    "    }\n",
    "    df['appId'] = None\n",
    "    for node_label, id_column in config.items():\n",
    "        df.loc[df['nodeLabels'] == node_label, 'appId'] = df.loc[\n",
    "            df['nodeLabels'] == node_label, id_column]\n",
    "    \n",
    "    return df\n",
    "\n",
    "## Add isSegmented to Fasta nodes\n",
    "def set_segmented(df):\n",
    "    df['isSegmented'] = None\n",
    "    df.loc[df['nodeLabels'] == 'Fasta', 'isSegmented'] = df.loc[\n",
    "        df['nodeLabels'] == 'Fasta', 'name'].apply(lambda x: '|Seg' in x)\n",
    "    \n",
    "\n",
    "enrich_data_with_tax_labels(nodes)\n",
    "set_node_app_id(nodes)\n",
    "set_segmented(nodes)\n",
    "\n",
    "assert nodes.shape[0] == NUMBER_OF_NODES\n",
    "nodes.to_csv(DATASET_DIR + 'pangenome_nodes.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export dataset edges from projection\n",
    "\n",
    "edges = pd.DataFrame()\n",
    "for unique_property in ['score', 'coverage', 'probab']:\n",
    "    edges = pd.concat([\n",
    "        edges,\n",
    "        gds.graph.relationshipProperties.stream(\n",
    "            get_projection(gds, get_projection_name(version)),\n",
    "            relationship_properties=[unique_property],\n",
    "        )\n",
    "    ])\n",
    "\n",
    "# reset index\n",
    "edges.reset_index(drop=True, inplace=True)\n",
    "\n",
    "assert edges.shape[0] == NUMBER_OF_EDGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enrich edges and save to csv\n",
    "\n",
    "node_map_cache = {}\n",
    "def set_edge_app_ids(df):\n",
    "    df_copy = df.copy()\n",
    "    df_copy['sourceAppId'] = None\n",
    "    df_copy['targetAppId'] = None\n",
    "    for i, row in df.iterrows():\n",
    "        if row['sourceNodeId'] not in node_map_cache:\n",
    "            node_map_cache[row['sourceNodeId']] = nodes.loc[nodes['nodeId'] == row['sourceNodeId'], 'appId'].values[0]\n",
    "        if row['targetNodeId'] not in node_map_cache:\n",
    "            node_map_cache[row['targetNodeId']] = nodes.loc[nodes['nodeId'] == row['targetNodeId'], 'appId'].values[0]\n",
    "\n",
    "        df_copy.at[i, 'sourceAppId'] = node_map_cache[row['sourceNodeId']]\n",
    "        df_copy.at[i, 'targetAppId'] = node_map_cache[row['targetNodeId']]\n",
    "\n",
    "        # if row['sourceNodeId'] == 44762:\n",
    "        #     # print(row['sourceNodeId'], node_map_cache[row['sourceNodeId']])\n",
    "        #     print(df_copy.at[i, 'sourceAppId'])\n",
    "\n",
    "        # if i > 100:\n",
    "        #     # print()\n",
    "        #     print(\n",
    "        #         df_copy.loc[df_copy['sourceNodeId'] == 44762, 'sourceAppId'],\n",
    "        #     )\n",
    "        #     break\n",
    "\n",
    "    return df_copy\n",
    "\n",
    "def set_edge_weights(df):\n",
    "    config = {\n",
    "        'hasHit': 'score',\n",
    "        'hasRegion': 'score',\n",
    "        'hasAffiliate': 'coverage',\n",
    "        'hasMember': 'probab',\n",
    "        'hasDownstream': 'score',\n",
    "    }\n",
    "    df['weight'] = None\n",
    "    for relationship_type, weight_column in config.items():\n",
    "        condition = (df['relationshipType'] == relationship_type) & (df['relationshipProperty'] == weight_column)\n",
    "        df.loc[condition, 'weight'] = df.loc[condition, 'propertyValue']\n",
    "    return df\n",
    "\n",
    "edges = set_edge_weights(edges)\n",
    "edges = set_edge_app_ids(edges)\n",
    "\n",
    "assert edges.shape[0] == NUMBER_OF_EDGES\n",
    "edges.to_csv(DATASET_DIR + 'pangenome_edges.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "graphName                                             dataset_projection_1\n",
       "database                                                             neo4j\n",
       "databaseLocation                                                     local\n",
       "memoryUsage                                                               \n",
       "sizeInBytes                                                             -1\n",
       "nodeCount                                                           148782\n",
       "relationshipCount                                                   787238\n",
       "configuration            {'relationshipProjection': {'hasHit': {'aggreg...\n",
       "density                                                           0.000036\n",
       "creationTime                           2024-04-30T23:10:29.592752103+00:00\n",
       "modificationTime                       2024-04-30T23:10:31.124691843+00:00\n",
       "schema                   {'graphProperties': {}, 'nodes': {'HitRegion':...\n",
       "schemaWithOrientation    {'graphProperties': {}, 'nodes': {'HitRegion':...\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop projection from Neo4j DB memory\n",
    "gds.graph.drop(get_projection_name())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export NCBI Taxonomy dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create taxonomy projection from existing serratus/SRA knowledge graph\n",
    "\n",
    "taxonomy_projection_name = 'taxonomy_projection'\n",
    "\n",
    "def get_taxon_nodes(gds):\n",
    "    if os.path.exists(DATASET_DIR + 'taxon_nodes.csv'):\n",
    "        return pd.read_csv(DATASET_DIR + 'taxon_nodes.csv')\n",
    "    query = '''\n",
    "            MATCH (n:Taxon)\n",
    "            RETURN\n",
    "                id(n) as nodeId,\n",
    "                n.taxId as appId,\n",
    "                n.taxId as taxId,\n",
    "                labels(n) as nodeLabels,\n",
    "                n.rank as rank,\n",
    "                n.taxKingdom as taxKingdom,\n",
    "                n.taxPhylum as taxPhylum,\n",
    "                n.taxOrder as taxOrder,\n",
    "                apoc.node.degree(n, \"HAS_PARENT\") as hasParentDegree,\n",
    "                apoc.node.degree(n, \"HAS_PARENT>\") as hasParentOutDegree,\n",
    "                apoc.node.degree(n, \"<HAS_PARENT\") as hasParentInDegree\n",
    "            '''\n",
    "    df = gds.run_cypher(query)\n",
    "    df['nodeLabels'] = df['nodeLabels'].apply(lambda x: ast.literal_eval(x)[0])\n",
    "    df.to_csv(DATASET_DIR + 'taxon_nodes.csv', index=False)\n",
    "    return df\n",
    "\n",
    "\n",
    "def get_taxon_has_parent_edges(gds):\n",
    "    if os.path.exists(DATASET_DIR + 'taxon_has_parent_edges.csv'):\n",
    "        return pd.read_csv(DATASET_DIR + 'taxon_has_parent_edges.csv')\n",
    "    query = '''\n",
    "            MATCH (s:Taxon)-[r:HAS_PARENT]->(t:Taxon)\n",
    "            RETURN\n",
    "                id(s) as sourceNodeId,\n",
    "                s.taxId as sourceAppId,\n",
    "                id(t) as targetNodeId,\n",
    "                t.taxId as targetAppId,\n",
    "                type(r) as relationshipType,\n",
    "                1 as weight\n",
    "            '''\n",
    "    df = gds.run_cypher(query)\n",
    "    df.to_csv(DATASET_DIR + 'taxon_has_parent_edges.csv', index=False)\n",
    "    return df\n",
    "\n",
    "kg_client = get_kg_connection()\n",
    "taxon_nodes = get_taxon_nodes(kg_client)\n",
    "taxon_has_parent_edges = get_taxon_has_parent_edges(kg_client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export node embeddings for testing\n",
    "\n",
    "def get_taxonomy_projection(gds, projection_name):\n",
    "    if gds.graph.exists(projection_name)['exists']:\n",
    "        return gds.graph.get(projection_name)\n",
    "    nodes = get_taxon_nodes(gds)\n",
    "    nodes = nodes.loc[\n",
    "        nodes['taxKingdom'] == 'Viruses'\n",
    "    ]\n",
    "    nodes['labels'] = nodes['nodeLabels']\n",
    "    nodes = nodes[[\n",
    "        'nodeId',\n",
    "        'labels',\n",
    "    ]]\n",
    "\n",
    "    relationships = get_taxon_has_parent_edges(gds)\n",
    "    relationships = relationships[[\n",
    "        'sourceNodeId',\n",
    "        'targetNodeId',\n",
    "        'relationshipType',\n",
    "        'weight'\n",
    "    ]]\n",
    "    undirected_relationship_types = relationships['relationshipType'].unique().tolist()\n",
    "    projection = gds.graph.construct(\n",
    "        graph_name=projection_name,\n",
    "        nodes=nodes,\n",
    "        relationships=relationships,\n",
    "        concurrency=4,\n",
    "        undirected_relationship_types=undirected_relationship_types,\n",
    "    )\n",
    "    return projection\n",
    "\n",
    "def delete_projection(gds, projection_name):\n",
    "    if gds.graph.exists(projection_name)['exists']:\n",
    "        gds.graph.drop(gds.graph.get(projection_name))\n",
    "\n",
    "def add_fastrp_embedding(gds, projection_name):\n",
    "    df_fastrp = gds.fastRP.mutate(\n",
    "        G=gds.graph.get(projection_name),\n",
    "        mutateProperty='fastrp',\n",
    "        randomSeed=42,\n",
    "        nodeLabels=[\n",
    "            'Taxon',\n",
    "        ],\n",
    "        relationshipTypes=[\n",
    "            \"HAS_PARENT\",\n",
    "        ],\n",
    "        embeddingDimension=128,\n",
    "        normalizationStrength=-0.5,\n",
    "    )\n",
    "\n",
    "def export_nodes_from_projection(gds, projection_name, property):\n",
    "    nodes = gds.graph.nodeProperties.stream(\n",
    "        get_projection(gds, projection_name),\n",
    "        node_properties=[property],\n",
    "        separate_property_columns=True,\n",
    "        db_node_properties=[\n",
    "            'taxId',\n",
    "            'rank',\n",
    "            'taxKingdom',\n",
    "            'taxPhylum',\n",
    "            'taxOrder',\n",
    "        ],\n",
    "        listNodeLabels=True,\n",
    "    )\n",
    "    nodes['nodeLabels'] = nodes['nodeLabels'].apply(lambda x: x[0])\n",
    "    return nodes\n",
    "\n",
    "\n",
    "def set_node_app_id(df):\n",
    "    config = {\n",
    "        'Taxon': 'taxId',\n",
    "    }\n",
    "    df['appId'] = None\n",
    "    for node_label, id_column in config.items():\n",
    "        df.loc[df['nodeLabels'] == node_label, 'appId'] = df.loc[\n",
    "            df['nodeLabels'] == node_label, id_column]\n",
    "    return df\n",
    "\n",
    "\n",
    "kg_client = get_kg_connection()\n",
    "delete_projection(gds, projection_name)\n",
    "projection = get_taxonomy_projection(kg_client, taxonomy_projection_name)\n",
    "add_fastrp_embedding(kg_client, taxonomy_projection_name)\n",
    "\n",
    "nodes = export_nodes_from_projection(kg_client, taxonomy_projection_name, 'fastrp')\n",
    "nodes = set_node_app_id(nodes)\n",
    "nodes.to_csv(DATASET_DIR + 'taxon_nodes_emb.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120\n"
     ]
    }
   ],
   "source": [
    "# Create Fasta to Taxon relationships\n",
    "\n",
    "def get_fasta_has_tax_order_edges(gds):\n",
    "    if os.path.exists(DATASET_DIR + 'fasta_has_taxon_taxon_edges.csv'):\n",
    "        return pd.read_csv(DATASET_DIR + 'fasta_has_taxon_taxon_edges.csv')\n",
    "\n",
    "    taxon_nodes = pd.read_csv(DATASET_DIR + 'taxon_nodes.csv')\n",
    "    order_nodes = taxon_nodes.loc[taxon_nodes['rank'] == 'order']\n",
    "\n",
    "    pangenome_nodes = pd.read_csv(DATASET_DIR + 'pangenome_nodes.csv')\n",
    "    fasta_nodes = pangenome_nodes.loc[pangenome_nodes['nodeLabels'] == 'Fasta']\n",
    "    \n",
    "    merged = pd.merge(\n",
    "        fasta_nodes,\n",
    "        order_nodes,\n",
    "        how='left',\n",
    "        left_on='order',\n",
    "        right_on='taxOrder',\n",
    "        suffixes=('', '_taxon')\n",
    "    )\n",
    "    \n",
    "    print(merged['taxOrder'].isna().sum())\n",
    "\n",
    "    rows = []\n",
    "    for i, fasta in merged.iterrows():\n",
    "        if pd.isna(fasta['taxOrder']):\n",
    "            continue\n",
    "        rows.append({\n",
    "            'sourceNodeId': fasta['nodeId'],\n",
    "            'targetNodeId': int(fasta['nodeId_taxon']),\n",
    "            'sourceAppId': fasta['appId'],\n",
    "            'targetAppId': int(fasta['appId_taxon']),\n",
    "            'relationshipType': 'HAS_TAX_ORDER',\n",
    "            'weight': 1,\n",
    "        })\n",
    "    df = pd.DataFrame(rows)\n",
    "    df.to_csv(DATASET_DIR + 'fasta_has_tax_order_edges.csv', index=False)\n",
    "    return df\n",
    "\n",
    "fasta_has_tax_order_edges = get_fasta_has_tax_order_edges(kg_client)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rnalab",
   "language": "python",
   "name": "rnalab"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
