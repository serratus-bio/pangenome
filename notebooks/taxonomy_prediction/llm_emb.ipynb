{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rnalab/ljp/.conda/envs/ljp/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_DIR = './dataset/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique Pfam accessions: 979\n"
     ]
    }
   ],
   "source": [
    "pangenome_nodes = pd.read_csv(DATASET_DIR + 'pangenome_nodes.csv')\n",
    "hit_family_nodes = pangenome_nodes[pangenome_nodes['nodeLabels'] == 'HitFamily']\n",
    "pfam_accessions = hit_family_nodes['accession'].unique()\n",
    "print('Number of unique Pfam accessions:', len(pfam_accessions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pfam_basic(accession):\n",
    "    acc_num = accession.split('PF')[1]\n",
    "    url = 'https://www.ncbi.nlm.nih.gov/Structure/cdd/cddsrv.cgi?uid=pfam' + acc_num\n",
    "    html = urlopen(url)\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    try:\n",
    "        desc = soup.find_all('meta', attrs={'name': 'description'})[0]['content']\n",
    "        desc = desc.split('Conserved Protein Domain Family')[1]\n",
    "        return desc\n",
    "    except:\n",
    "        print('No description found for ' + accession)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "977 Pfams to fetch\n"
     ]
    }
   ],
   "source": [
    "# Write rows to CSV continuously and start from last written\n",
    "\n",
    "import csv\n",
    "\n",
    "fetch_pfams = sorted(pfam_accessions)\n",
    "filename = DATASET_DIR + 'pfam_llm.csv'\n",
    "try:\n",
    "    pfam_descriptions = pd.read_csv(filename)\n",
    "    last_written = pfam_descriptions['accession'].values[-1]\n",
    "    last_written_index = fetch_pfams.index(last_written)\n",
    "    fetch_pfams = fetch_pfams[last_written_index + 1:]\n",
    "except:\n",
    "    with open(filename, 'w', newline=\"\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(['accession', 'description'])\n",
    "\n",
    "print(len(fetch_pfams), 'Pfams to fetch')\n",
    "\n",
    "for pfam in fetch_pfams:\n",
    "    with open(filename, 'a', newline=\"\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([pfam, get_pfam_basic(pfam)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique orders: 65\n"
     ]
    }
   ],
   "source": [
    "taxon_nodes = pd.read_csv(DATASET_DIR + 'taxon_nodes.csv')\n",
    "taxon_nodes = taxon_nodes.loc[\n",
    "    taxon_nodes['taxKingdom'] == 'Viruses'\n",
    "]\n",
    "taxon_orders = taxon_nodes[taxon_nodes['rank'] == 'order']['taxOrder'].unique()\n",
    "print('Number of unique orders:', len(taxon_orders))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jingchuvirales is an order of viruses. The order contains the following families:[1] This virus-related article is a stub. You can help Wikipedia by expanding it.\n"
     ]
    }
   ],
   "source": [
    "def get_taxon_order_description(order):\n",
    "    # url = f'https://ictv.global/report/chapter/{str(order)}/{str(order)}'\n",
    "    try:\n",
    "        url = f'https://en.wikipedia.org/wiki/{order}'\n",
    "        html = urlopen(url)\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        text = ''\n",
    "        for i in soup.select('p'):\n",
    "            text += i.text\n",
    "        text = text.strip()\n",
    "        text = text.replace('\\n', ' ')\n",
    "        return text\n",
    "    except:\n",
    "        print('No description found for ' + order)\n",
    "        return None\n",
    "\n",
    "test = get_taxon_order_description('Jingchuvirales')\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65 Taxon orders to fetch\n",
      "No description found for Crassvirales\n",
      "No description found for Kirjokansivirales\n",
      "No description found for Methanobavirales\n",
      "No description found for Rivendellvirales\n",
      "No description found for Rohanvirales\n",
      "No description found for Thumleimavirales\n",
      "No description found for Yadokarivirales\n"
     ]
    }
   ],
   "source": [
    "fetch_taxons = sorted(taxon_orders)\n",
    "filename = DATASET_DIR + 'taxon_order_llm.csv'\n",
    "\n",
    "try:\n",
    "    taxon_order_descriptions = pd.read_csv(filename)\n",
    "    last_written = taxon_order_descriptions['order'].values[-1]\n",
    "    last_written_index = fetch_taxons.index(last_written)\n",
    "    fetch_taxons = fetch_taxons[last_written_index + 1:]\n",
    "except:\n",
    "    with open(filename, 'w', newline=\"\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(['taxId', 'order', 'description'])\n",
    "    \n",
    "print(len(fetch_taxons), 'Taxon orders to fetch')\n",
    "\n",
    "for tax_order in fetch_taxons:\n",
    "    with open(filename, 'a', newline=\"\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        tax_id = taxon_nodes[taxon_nodes['taxOrder'] == tax_order]['taxId'].values[0]\n",
    "        writer.writerow([tax_id, tax_order, get_taxon_order_description(tax_order)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rnalab/ljp/.conda/envs/ljp/lib/python3.8/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_embedding_to_df(df, text_column):\n",
    "    embeddings = model.encode(df[text_column].values)\n",
    "\n",
    "    df['embeddings'] = embeddings.tolist()\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxon_order_descriptions = pd.read_csv(DATASET_DIR + 'taxon_order_llm.csv')\n",
    "\n",
    "taxon_order_descriptions = add_embedding_to_df(taxon_order_descriptions, 'description')\n",
    "taxon_order_descriptions.to_csv(DATASET_DIR + 'taxon_order_llm.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "pfam_descriptions = pd.read_csv(DATASET_DIR + 'pfam_llm.csv')\n",
    "\n",
    "pfam_descriptions = add_embedding_to_df(pfam_descriptions, 'description')\n",
    "pfam_descriptions.to_csv(DATASET_DIR + 'pfam_llm.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "\n",
    "# \"microsoft/BioGPT-Large\"\n",
    "# \"microsoft/biogpt\"\n",
    "model_name = 'sentence-transformers/all-MiniLM-L6-v2'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "\n",
    "pipe = pipeline('feature-extraction', model=model, tokenizer=tokenizer)\n",
    "def get_embedding(text):\n",
    "    data = pipe(text, return_tensors=\"pt\")\n",
    "    return data[0].numpy().mean(axis=0)\n",
    "    \n",
    "out = get_embedding('This is a test.')\n",
    "# 57717, 42384\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rnalab/ljp/.conda/envs/ljp/lib/python3.8/site-packages/numba/np/ufunc/parallel.py:371: NumbaWarning: The TBB threading layer requires TBB version 2021 update 6 or later i.e., TBB_INTERFACE_VERSION >= 12060. Found TBB_INTERFACE_VERSION = 12050. The TBB threading layer is disabled.\n",
      "  warnings.warn(problem)\n",
      "/home/rnalab/ljp/.conda/envs/ljp/lib/python3.8/site-packages/umap/umap_.py:2437: UserWarning: n_neighbors is larger than the dataset size; truncating to X.shape[0] - 1\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rnalab/ljp/.conda/envs/ljp/lib/python3.8/site-packages/umap/umap_.py:134: UserWarning: A large number of your vertices were disconnected from the manifold.\n",
      "Disconnection_distance = inf has removed 0 edges.\n",
      "It has fully disconnected 2 vertices.\n",
      "You might consider using find_disconnected_points() to find and remove these points from your data.\n",
      "Use umap.utils.disconnected_vertices() to identify them.\n",
      "  warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "zero-size array to reduction operation maximum which has no identity",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[156], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m umap_emb \u001b[38;5;241m=\u001b[39m \u001b[43mreducer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mscatter(\n\u001b[1;32m      4\u001b[0m     umap_emb[:, \u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m      5\u001b[0m     umap_emb[:, \u001b[38;5;241m1\u001b[39m],\n\u001b[1;32m      6\u001b[0m     s\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m,\n\u001b[1;32m      7\u001b[0m     alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m,\n\u001b[1;32m      8\u001b[0m )\n",
      "File \u001b[0;32m~/.conda/envs/ljp/lib/python3.8/site-packages/umap/umap_.py:2891\u001b[0m, in \u001b[0;36mUMAP.fit_transform\u001b[0;34m(self, X, y, force_all_finite)\u001b[0m\n\u001b[1;32m   2855\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit_transform\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, force_all_finite\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m   2856\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Fit X into an embedded space and return that transformed\u001b[39;00m\n\u001b[1;32m   2857\u001b[0m \u001b[38;5;124;03m    output.\u001b[39;00m\n\u001b[1;32m   2858\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2889\u001b[0m \u001b[38;5;124;03m        Local radii of data points in the embedding (log-transformed).\u001b[39;00m\n\u001b[1;32m   2890\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2891\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2892\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124membedding\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   2893\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_dens:\n",
      "File \u001b[0;32m~/.conda/envs/ljp/lib/python3.8/site-packages/umap/umap_.py:2784\u001b[0m, in \u001b[0;36mUMAP.fit\u001b[0;34m(self, X, y, force_all_finite)\u001b[0m\n\u001b[1;32m   2780\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124membedding\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   2781\u001b[0m     epochs \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   2782\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_epochs_list \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_epochs_list \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_epochs\n\u001b[1;32m   2783\u001b[0m     )\n\u001b[0;32m-> 2784\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding_, aux_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_embed_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2785\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raw_data\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2786\u001b[0m \u001b[43m        \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2787\u001b[0m \u001b[43m        \u001b[49m\u001b[43minit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2788\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# JH why raw data?\u001b[39;49;00m\n\u001b[1;32m   2789\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2791\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_epochs_list \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2792\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124membedding_list\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m aux_data:\n",
      "File \u001b[0;32m~/.conda/envs/ljp/lib/python3.8/site-packages/umap/umap_.py:2830\u001b[0m, in \u001b[0;36mUMAP._fit_embed_data\u001b[0;34m(self, X, n_epochs, init, random_state)\u001b[0m\n\u001b[1;32m   2826\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_fit_embed_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, n_epochs, init, random_state):\n\u001b[1;32m   2827\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"A method wrapper for simplicial_set_embedding that can be\u001b[39;00m\n\u001b[1;32m   2828\u001b[0m \u001b[38;5;124;03m    replaced by subclasses.\u001b[39;00m\n\u001b[1;32m   2829\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2830\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msimplicial_set_embedding\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2831\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2832\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgraph_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2833\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_components\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2834\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_initial_alpha\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2835\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_a\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2836\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_b\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2837\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrepulsion_strength\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2838\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnegative_sample_rate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2839\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2840\u001b[0m \u001b[43m        \u001b[49m\u001b[43minit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2841\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2842\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_input_distance_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2843\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_metric_kwds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2844\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdensmap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2845\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_densmap_kwds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2846\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_dens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2847\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_output_distance_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2848\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_output_metric_kwds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2849\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_metric\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43meuclidean\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43ml2\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2850\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom_state\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   2851\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2852\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtqdm_kwds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtqdm_kwds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2853\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/ljp/lib/python3.8/site-packages/umap/umap_.py:1087\u001b[0m, in \u001b[0;36msimplicial_set_embedding\u001b[0;34m(data, graph, n_components, initial_alpha, a, b, gamma, negative_sample_rate, n_epochs, init, random_state, metric, metric_kwds, densmap, densmap_kwds, output_dens, output_metric, output_metric_kwds, euclidean_output, parallel, verbose, tqdm_kwds)\u001b[0m\n\u001b[1;32m   1084\u001b[0m n_epochs_max \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(n_epochs) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(n_epochs, \u001b[38;5;28mlist\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m n_epochs\n\u001b[1;32m   1086\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_epochs_max \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m10\u001b[39m:\n\u001b[0;32m-> 1087\u001b[0m     graph\u001b[38;5;241m.\u001b[39mdata[graph\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m<\u001b[39m (\u001b[43mgraph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mfloat\u001b[39m(n_epochs_max))] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[1;32m   1088\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1089\u001b[0m     graph\u001b[38;5;241m.\u001b[39mdata[graph\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m<\u001b[39m (graph\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mmax() \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mfloat\u001b[39m(default_epochs))] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n",
      "File \u001b[0;32m~/.conda/envs/ljp/lib/python3.8/site-packages/numpy/core/_methods.py:41\u001b[0m, in \u001b[0;36m_amax\u001b[0;34m(a, axis, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_amax\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     40\u001b[0m           initial\u001b[38;5;241m=\u001b[39m_NoValue, where\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m---> 41\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mumr_maximum\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhere\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mValueError\u001b[0m: zero-size array to reduction operation maximum which has no identity"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "import umap\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "reducer = umap.UMAP()\n",
    "emb = pfam_descriptions['embeddings'].values\n",
    "\n",
    "umap_emb = reducer.fit_transform(x)\n",
    "\n",
    "plt.scatter(\n",
    "    umap_emb[:, 0],\n",
    "    umap_emb[:, 1],\n",
    "    s=10,\n",
    "    alpha=0.5,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ljp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
